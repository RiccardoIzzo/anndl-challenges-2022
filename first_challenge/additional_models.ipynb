{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Honorable Mentions\n",
    "We insert our former experimental models that kicked off our research of the best model we could create.\n",
    "More in detail, we present here:\n",
    "* Our best performing attempt as a custom model\n",
    "* Another attempt at transfer learning and fine tuning but exploiting VGG19 instead of Xception\n",
    "\n",
    "Both of them share the same Data Augmentation routine that the straight forward Xception transfer model uses, so we report here only the functions building the actual model, while omitting the data pre-processing although it has been performed.\n",
    "\n",
    "## Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model made with only maxpoolings and convolutions, also add some regularization in order to achieve better performances\n",
    "# There is a batch normalization after each convolution and before the relu\n",
    "# There is a dropout layer after every maxpooling with 0.2\n",
    "\n",
    "epochs = 200\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "def build_model(input_shape):\n",
    "\n",
    "    #input layer of the CNN\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "\n",
    "\n",
    "    # Convolutional part\n",
    "    conv1 = tfkl.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        kernel_initializer='he_uniform'\n",
    "    )(input_layer)\n",
    "\n",
    "    bn1 = tfkl.BatchNormalization()(conv1)\n",
    "\n",
    "    relu1 = tfkl.Activation('relu')(bn1)\n",
    "\n",
    "    pool1 = tfkl.MaxPooling2D(\n",
    "        pool_size=2,\n",
    "        strides=3\n",
    "    )(relu1)\n",
    "\n",
    "    dp1 = tfkl.Dropout(0.2)(pool1)\n",
    "\n",
    "    conv2 = tfkl.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        kernel_initializer='he_uniform'\n",
    "    )(dp1)\n",
    "\n",
    "    bn2 = tfkl.BatchNormalization()(conv2)\n",
    "\n",
    "    relu2 = tfkl.Activation('relu')(bn2)\n",
    "\n",
    "    conv3 = tfkl.Conv2D(\n",
    "        filters=256,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer='he_uniform'\n",
    "    )(relu2)\n",
    "\n",
    "    bn3 = tfkl.BatchNormalization()(conv3)\n",
    "\n",
    "    relu3 = tfkl.Activation('relu')(bn3)\n",
    "\n",
    "    pool2 = tfkl.MaxPooling2D(\n",
    "        pool_size=(2, 2),\n",
    "        strides=2\n",
    "    )(relu3)\n",
    "\n",
    "    dp2 = tfkl.Dropout(0.2)(pool2)\n",
    "\n",
    "    conv4 = tfkl.Conv2D(\n",
    "        filters=512,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        activation='relu',\n",
    "        kernel_initializer='he_uniform'\n",
    "    )(dp2)\n",
    "\n",
    "    bn4 = tfkl.BatchNormalization()(conv4)\n",
    "\n",
    "    relu4 = tfkl.Activation('relu')(bn4)\n",
    "\n",
    "    pool3 = tfkl.MaxPooling2D(\n",
    "        pool_size=(2, 2),\n",
    "        strides=2\n",
    "    )(relu4)\n",
    "\n",
    "    dp3 = tfkl.Dropout(0.2)(pool3)\n",
    "\n",
    "\n",
    "    # Global average pooling in order to prepare data to feed the FC part\n",
    "    global_average = tfkl.GlobalAveragePooling2D()(dp3)\n",
    "\n",
    "\n",
    "    # FC part \n",
    "    dense1 = tfkl.Dense(units=128, activation='relu', kernel_initializer='he_uniform')(global_average)\n",
    "\n",
    "    bn6 = tfkl.BatchNormalization()(dense1)\n",
    "\n",
    "    dp4 = tfkl.Dropout(0.5)(bn6)\n",
    "    \n",
    "    rff = RandomFourierFeatures(output_dim=4096, scale=10.0, kernel_initializer=\"gaussian\")(dp4)\n",
    "\n",
    "    output_layer = tfkl.Dense(units=8, activation='softmax', kernel_initializer='he_uniform',\n",
    "                              name='Output')(rff)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-3), metrics='accuracy')\n",
    "\n",
    "    # Return the model\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "# Create folders and callbacks\n",
    "locals_callbacks = create_folders_and_callbacks(model_name='Model-v0')\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    training_set,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_set,\n",
    "    callbacks=locals_callbacks\n",
    ").history\n",
    "\n",
    "# Save best epoch model\n",
    "model.save(\"/kaggle/working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19 Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning with VGG19\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "\n",
    "epochs = 150\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Import VGG19 pretrained application without the FC part\n",
    "\n",
    "base_model = VGG19(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=8,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "# Freeze every layer in the net\n",
    "base_model.trainable = False\n",
    "\n",
    "def build_model(input_shape):\n",
    "    # Use the VGG19 feature extraction part\n",
    "    x = base_model.output\n",
    "\n",
    "    #Build a custom FC part\n",
    "    global_average = tfkl.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    dense1 = tfkl.Dense(units=512, activation='relu', kernel_initializer='he_uniform')(global_average)\n",
    "\n",
    "    bn6 = tfkl.BatchNormalization()(dense1)\n",
    "\n",
    "    dp4 = tfkl.Dropout(0.5)(bn6)\n",
    "\n",
    "    output_layer = tfkl.Dense(units=8, activation='softmax', kernel_initializer='he_uniform',\n",
    "                              name='Output')(dp4)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=base_model.input, outputs=output_layer, name='model')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-3), metrics='accuracy')\n",
    "\n",
    "    # Return the model\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(input_shape)\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Create folders and callbacks and fit\n",
    "locals_callbacks = create_folders_and_callbacks(model_name='VGG19_0')\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "\ttraining_set,\n",
    "\tepochs=epochs,\n",
    "\tvalidation_data=validation_set,\n",
    "\tcallbacks=locals_callbacks\n",
    ").history\n",
    "\n",
    "# Fine tuning part\n",
    "\n",
    "# Unfreeze number of layer in the VGG19\n",
    "for layer in model.layers[:3]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[3:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile the model with very low learning rate\n",
    "model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-5), metrics='accuracy')\n",
    "\n",
    "# Callbacks\n",
    "locals_callbacks1 = create_folders_and_callbacks(model_name='VGG19_0')\n",
    "\n",
    "# Retrain the model\n",
    "history = model.fit(\n",
    "\ttraining_set,\n",
    "\tepochs=epochs,\n",
    "\tvalidation_data=validation_set,\n",
    "\tcallbacks=locals_callbacks1\n",
    ").history\n",
    "\n",
    "# Save model\n",
    "model.save(\"/kaggle/output/working/VGG19_0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
